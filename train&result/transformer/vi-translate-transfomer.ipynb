{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-31T11:07:22.947451Z",
     "iopub.status.busy": "2025-05-31T11:07:22.947296Z",
     "iopub.status.idle": "2025-05-31T11:07:31.461759Z",
     "shell.execute_reply": "2025-05-31T11:07:31.460994Z",
     "shell.execute_reply.started": "2025-05-31T11:07:22.947436Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!cp -r \"/kaggle/input/vi-tone-no-tone/data\" /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-31T11:07:59.567217Z",
     "iopub.status.busy": "2025-05-31T11:07:59.566918Z",
     "iopub.status.idle": "2025-05-31T11:08:31.258339Z",
     "shell.execute_reply": "2025-05-31T11:08:31.257573Z",
     "shell.execute_reply.started": "2025-05-31T11:07:59.567184Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in train_dataset: 4393646\n",
      "Number of sentences in val_dataset: 549205\n",
      "Number of sentences in test_dataset: 549207\n",
      "Expected train batches: 34326\n",
      "Input vocab size: 1450\n",
      "Output vocab size: 5805\n",
      "Sample input vocab: [('a', 0), ('ac', 1), ('ach', 2), ('ai', 3), ('am', 4)]\n",
      "Sample output vocab: [('a', 0), ('a1', 1), ('a1c', 2), ('a1ch', 3), ('a1i', 4)]\n",
      "Value of <pad>: 5802\n",
      "Sample source: ['tenedos barronus uoc ralph vary chamberlin mieu ta nam', 'ngay giao su tran van huong uoc quoc truong phan khac suu bo nhiem lam thu tuong', 'trong noi inh cac vi quy nhan cung cung tan co ngau nhien lam sai ieu gi quach hau cung khong truy cuu con o truoc mat tao phi bao che', 'chung uoc su dung cho che tao cac cam bien tia hong ngoai hoac nhiet ien', 'uchukeiji gyaban uoc bat au tu mot tam hinh minh hoa cua murakami katsushi mot nhan vien thiet ke cua hang bandai nguoi a e lai ten tuoi minh trong lich su nganh o choi voi nhieu san pham oc ao']\n",
      "Sample target: ['tenedos barronus d9u7o75c ralph vary chamberlin mie6u ta3 na8m', 'nga2y gia1o su7 tra62n va8n hu7o7ng d9u7o75c quo61c tru7o73ng phan kha81c su73u bo63 nhie65m la2m thu3 tu7o71ng', 'trong no65i d9i2nh ca1c vi5 quy1 nha6n cu2ng cung ta62n co1 nga64u nhie6n la2m sai d9ie62u gi2 qua1ch ha65u cu4ng kho6ng truy cu71u co2n o73 tru7o71c ma85t ta2o phi bao che', 'chu1ng d9u7o75c su73 du5ng cho che61 ta5o ca1c ca3m bie61n tia ho62ng ngoa5i hoa85c nhie65t d9ie65n', 'uchukeiji gyaban d9u7o75c ba81t d9a62u tu72 mo65t ta61m hi2nh minh ho5a cu3a murakami katsushi mo65t nha6n vie6n thie61t ke61 cu3a ha4ng bandai ngu7o72i d9a4 d9e63 la5i te6n tuo63i mi2nh trong li5ch su73 nga2nh d9o62 cho7i vo71i nhie62u sa3n pha63m d9o65c d9a1o']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tạo thư mục lưu kết quả\n",
    "os.makedirs(\"/kaggle/working/results\", exist_ok=True)\n",
    "\n",
    "# Định nghĩa lớp Dataset\n",
    "class TranslationDatasetFull(Dataset):\n",
    "    def __init__(self, in_file, out_file, in_vocab, out_vocab, max_len=50):\n",
    "        self.in_sentences = self._load_sentences(in_file)\n",
    "        self.out_sentences = self._load_sentences(out_file)\n",
    "        self.in_vocab = self._load_vocab(in_vocab) if isinstance(in_vocab, str) else in_vocab\n",
    "        self.out_vocab = self._load_vocab(out_vocab) if isinstance(out_vocab, str) else out_vocab\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def _load_sentences(self, file_path):\n",
    "        df = pd.read_csv(file_path, encoding='utf-8', header=None, names=['ID', 'Sentence'])\n",
    "        sentences = df['Sentence'].tolist()\n",
    "        return [str(s).strip() for s in sentences if str(s).strip()]\n",
    "\n",
    "    def _load_vocab(self, vocab_path):\n",
    "        vocab = {}\n",
    "        with open(vocab_path, 'r', encoding='utf-8') as f:\n",
    "            words = [line.strip() for line in f if line.strip()]\n",
    "        for idx, word in enumerate(words):\n",
    "            vocab[word] = idx\n",
    "        required_tokens = ['<unk>', '<pad>', '<sos>', '<eos>']\n",
    "        max_idx = max(vocab.values()) if vocab else -1\n",
    "        for token in required_tokens:\n",
    "            if token not in vocab:\n",
    "                max_idx += 1\n",
    "                vocab[token] = max_idx\n",
    "        return vocab\n",
    "\n",
    "    def _encode_sentence(self, sentence, vocab, max_len):\n",
    "        tokens = sentence.strip().split()\n",
    "        token_ids = [vocab.get(token, vocab['<unk>']) for token in tokens]\n",
    "        token_ids = token_ids[:max_len] + [vocab['<pad>']] * (max_len - len(token_ids))\n",
    "        return token_ids\n",
    "\n",
    "    def _encode_decoder_sentence(self, sentence, vocab, max_len):\n",
    "        tokens = sentence.strip().split()\n",
    "        full_tokens = [vocab['<sos>']] + [vocab.get(token, vocab['<unk>']) for token in tokens] + [vocab['<eos>']]\n",
    "        if len(full_tokens) < max_len:\n",
    "            full_tokens += [vocab['<pad>']] * (max_len - len(full_tokens))\n",
    "        else:\n",
    "            full_tokens = full_tokens[:max_len]\n",
    "        return full_tokens\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.in_sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        in_sentence = self.in_sentences[idx]\n",
    "        out_sentence = self.out_sentences[idx]\n",
    "        src = self._encode_sentence(in_sentence, self.in_vocab, self.max_len)\n",
    "        tgt = self._encode_decoder_sentence(out_sentence, self.out_vocab, self.max_len)\n",
    "        return torch.tensor(src, dtype=torch.long), torch.tensor(tgt, dtype=torch.long)\n",
    "\n",
    "# Custom collate function to enforce max_len\n",
    "def collate_fn(batch):\n",
    "    max_len = 50  # Enforce MAX_LEN\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src, tgt in batch:\n",
    "        src = src[:max_len]\n",
    "        tgt = tgt[:max_len]\n",
    "        src_batch.append(src)\n",
    "        tgt_batch.append(tgt)\n",
    "    src_batch = torch.stack(src_batch)\n",
    "    tgt_batch = torch.stack(tgt_batch)\n",
    "    return src_batch, tgt_batch\n",
    "\n",
    "# Tạo dataset và DataLoader\n",
    "train_dataset = TranslationDatasetFull(\n",
    "    \"/kaggle/working/data/train/source.csv\",\n",
    "    \"/kaggle/working/data/train/target.csv\",\n",
    "    \"/kaggle/working/data/vocab/input_vocab.txt\",\n",
    "    \"/kaggle/working/data/vocab/output_vocab.txt\",\n",
    "    max_len=50\n",
    ")\n",
    "val_dataset = TranslationDatasetFull(\n",
    "    \"/kaggle/working/data/val/source.csv\",\n",
    "    \"/kaggle/working/data/val/target.csv\",\n",
    "    \"/kaggle/working/data/vocab/input_vocab.txt\",\n",
    "    \"/kaggle/working/data/vocab/output_vocab.txt\",\n",
    "    max_len=50\n",
    ")\n",
    "test_dataset = TranslationDatasetFull(\n",
    "    \"/kaggle/working/data/test/source.csv\",\n",
    "    \"/kaggle/working/data/test/target.csv\",\n",
    "    \"/kaggle/working/data/vocab/input_vocab.txt\",\n",
    "    \"/kaggle/working/data/vocab/output_vocab.txt\",\n",
    "    max_len=50\n",
    ")\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=2, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=2, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=2, collate_fn=collate_fn)\n",
    "\n",
    "# Debug dataset và vocab\n",
    "print(f\"Number of sentences in train_dataset: {len(train_dataset)}\")\n",
    "print(f\"Number of sentences in val_dataset: {len(val_dataset)}\")\n",
    "print(f\"Number of sentences in test_dataset: {len(test_dataset)}\")\n",
    "print(f\"Expected train batches: {len(train_loader)}\")\n",
    "print(\"Input vocab size:\", len(train_dataset.in_vocab))\n",
    "print(\"Output vocab size:\", len(train_dataset.out_vocab))\n",
    "print(\"Sample input vocab:\", list(train_dataset.in_vocab.items())[:5])\n",
    "print(\"Sample output vocab:\", list(train_dataset.out_vocab.items())[:5])\n",
    "print(\"Value of <pad>:\", train_dataset.out_vocab.get('<pad>', \"Not found\"))\n",
    "print(\"Sample source:\", train_dataset.in_sentences[:5])\n",
    "print(\"Sample target:\", train_dataset.out_sentences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-31T23:07:15.239Z",
     "iopub.execute_input": "2025-05-31T11:09:08.129702Z",
     "iopub.status.busy": "2025-05-31T11:09:08.128816Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tTrain Loss: 1.696\n",
      "\tVal Loss: 0.918\n",
      "\tVal Accuracy: 0.756\n",
      "\tVal BLEU: 0.595\n",
      "\tEpoch Time: 11593.25 seconds\n",
      "\tVRAM allocated: 425.98 MB\n",
      "Epoch: 02\n",
      "\tTrain Loss: 0.969\n",
      "\tVal Loss: 0.543\n",
      "\tVal Accuracy: 0.850\n",
      "\tVal BLEU: 0.713\n",
      "\tEpoch Time: 11534.57 seconds\n",
      "\tVRAM allocated: 425.98 MB\n",
      "Epoch: 03\n",
      "\tTrain Loss: 0.634\n",
      "\tVal Loss: 0.342\n",
      "\tVal Accuracy: 0.904\n",
      "\tVal BLEU: 0.798\n",
      "\tEpoch Time: 11569.35 seconds\n",
      "\tVRAM allocated: 425.98 MB\n"
     ]
    }
   ],
   "source": [
    "# Define Transformer Model\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "DIM_MODEL = 512\n",
    "N_HEADS = 8\n",
    "N_LAYERS = 4\n",
    "D_FF = 512\n",
    "DROPOUT = 0.1\n",
    "MAX_LEN = 50\n",
    "NUM_EPOCHS = 6\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.depth = d_model // n_heads\n",
    "\n",
    "        self.query_linear = nn.Linear(d_model, d_model)\n",
    "        self.key_linear = nn.Linear(d_model, d_model)\n",
    "        self.value_linear = nn.Linear(d_model, d_model)\n",
    "        self.out_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = x.view(batch_size, -1, self.n_heads, self.depth)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None, padding_mask=None):\n",
    "        batch_size = query.size(0)\n",
    "        query_len = query.size(1)\n",
    "        key_len = key.size(1)\n",
    "\n",
    "        query = self.split_heads(self.query_linear(query), batch_size)  # [batch_size, n_heads, query_len, depth]\n",
    "        key = self.split_heads(self.key_linear(key), batch_size)        # [batch_size, n_heads, key_len, depth]\n",
    "        value = self.split_heads(self.value_linear(value), batch_size)  # [batch_size, n_heads, key_len, depth]\n",
    "\n",
    "        attention_scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(self.depth)  # [batch_size, n_heads, query_len, key_len]\n",
    "\n",
    "        # Áp dụng padding mask (ngăn attention đến các vị trí pad)\n",
    "        if padding_mask is not None:\n",
    "            # padding_mask: [batch_size, key_len]\n",
    "            padding_mask = padding_mask.unsqueeze(1).unsqueeze(2)  # [batch_size, 1, 1, key_len]\n",
    "            attention_scores = attention_scores.masked_fill(padding_mask == 1, float('-inf'))\n",
    "\n",
    "        # Áp dụng causal mask hoặc source mask (nếu có)\n",
    "        if mask is not None:\n",
    "            # mask: [key_len, key_len] hoặc [query_len, key_len]\n",
    "            if len(mask.shape) == 2:\n",
    "                mask = mask.unsqueeze(0).unsqueeze(1)  # [1, 1, query_len/key_len, key_len]\n",
    "                mask = mask.repeat(batch_size, self.n_heads, 1, 1)  # [batch_size, n_heads, query_len/key_len, key_len]\n",
    "            elif len(mask.shape) == 3:\n",
    "                mask = mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1)  # [batch_size, n_heads, query_len/key_len, key_len]\n",
    "            # Đảm bảo kích thước của mask phù hợp với attention_scores\n",
    "            if mask.size(2) != query_len or mask.size(3) != key_len:\n",
    "                mask = mask[:, :, :query_len, :key_len]\n",
    "            attention_scores = attention_scores + mask\n",
    "\n",
    "        attention_weights = F.softmax(attention_scores, dim=-1)\n",
    "        context = torch.matmul(attention_weights, value)  # [batch_size, n_heads, query_len, depth]\n",
    "        context = context.permute(0, 2, 1, 3).contiguous().view(batch_size, query_len, self.d_model)\n",
    "        output = self.out_linear(context)\n",
    "        return output\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear2(self.dropout(F.relu(self.linear1(x))))\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.attention = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None, padding_mask=None):\n",
    "        attn_output = self.attention(x, x, x, mask=mask, padding_mask=padding_mask)\n",
    "        x = self.layer_norm1(x + self.dropout(attn_output))\n",
    "        ffn_output = self.ffn(x)\n",
    "        x = self.layer_norm2(x + self.dropout(ffn_output))\n",
    "        return x\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attention = MultiHeadAttention(d_model, n_heads)\n",
    "        self.cross_attention = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_output, src_mask=None, tgt_mask=None, src_padding_mask=None, tgt_padding_mask=None):\n",
    "        # Self-attention với target (causal mask)\n",
    "        self_attn_output = self.self_attention(x, x, x, mask=tgt_mask, padding_mask=tgt_padding_mask)\n",
    "        x = self.layer_norm1(x + self.dropout(self_attn_output))\n",
    "\n",
    "        # Cross-attention với encoder output\n",
    "        cross_attn_output = self.cross_attention(x, enc_output, enc_output, mask=src_mask, padding_mask=src_padding_mask)\n",
    "        x = self.layer_norm2(x + self.dropout(cross_attn_output))\n",
    "\n",
    "        # Feed-forward\n",
    "        ffn_output = self.ffn(x)\n",
    "        x = self.layer_norm3(x + self.dropout(ffn_output))\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, n_heads, n_layers, d_ff, max_len=5000, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.positional_encoding = self._generate_positional_encoding(max_len, d_model)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def _generate_positional_encoding(self, max_len, d_model):\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # [1, max_len, d_model]\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x, mask=None, padding_mask=None):\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "        seq_len = x.size(1)\n",
    "        x = x + self.positional_encoding[:, :seq_len, :].to(x.device)\n",
    "        x = self.dropout(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask=mask, padding_mask=padding_mask)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, n_heads, n_layers, d_ff, max_len=5000, dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.positional_encoding = self._generate_positional_encoding(max_len, d_model)\n",
    "        self.layers = nn.ModuleList([DecoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.output_linear = nn.Linear(d_model, vocab_size)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def _generate_positional_encoding(self, max_len, d_model):\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # [1, max_len, d_model]\n",
    "        return pe\n",
    "\n",
    "    def forward(self, x, enc_output, src_mask=None, tgt_mask=None, src_padding_mask=None, tgt_padding_mask=None):\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "        seq_len = x.size(1)\n",
    "        x = x + self.positional_encoding[:, :seq_len, :].to(x.device)\n",
    "        x = self.dropout(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, enc_output, src_mask=src_mask, tgt_mask=tgt_mask, src_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask)\n",
    "        logits = self.output_linear(x)\n",
    "        return logits\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, n_heads, n_layers, d_ff, max_len=5000, dropout=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder(src_vocab_size, d_model, n_heads, n_layers, d_ff, max_len, dropout)\n",
    "        self.decoder = Decoder(tgt_vocab_size, d_model, n_heads, n_layers, d_ff, max_len, dropout)\n",
    "\n",
    "    def forward(self, src, tgt, src_mask=None, tgt_mask=None, src_padding_mask=None, tgt_padding_mask=None):\n",
    "        enc_output = self.encoder(src, mask=src_mask, padding_mask=src_padding_mask)\n",
    "        logits = self.decoder(tgt, enc_output, src_mask=src_mask, tgt_mask=tgt_mask, src_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask)\n",
    "        return logits\n",
    "\n",
    "# Generate target mask for causal attention\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "# Greedy decoding for inference\n",
    "def greedy_decode(model, src, src_mask, src_padding_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "    src_padding_mask = src_padding_mask.to(DEVICE)\n",
    "    \n",
    "    memory = model.encoder(src, mask=src_mask, padding_mask=src_padding_mask)\n",
    "    \n",
    "    ys = torch.ones(src.size(0), 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    \n",
    "    for i in range(max_len - 1):\n",
    "        tgt_mask = generate_square_subsequent_mask(ys.size(1)).to(DEVICE)\n",
    "        tgt_padding_mask = (ys == train_dataset.out_vocab['<pad>']).to(DEVICE)\n",
    "        out = model.decoder(ys, memory, src_mask=src_mask, tgt_mask=tgt_mask, src_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask)\n",
    "        prob = out[:, -1, :]\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "        ys = torch.cat([ys, torch.tensor([[next_word]], device=DEVICE)], dim=1)\n",
    "        if next_word == train_dataset.out_vocab['<eos>']:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "# Vocabulary class for token lookup\n",
    "class SimpleVocab:\n",
    "    def __init__(self, vocab):\n",
    "        self.vocab = vocab\n",
    "        self.inv_vocab = {id: token for token, id in vocab.items()}\n",
    "    def lookup_tokens(self, ids):\n",
    "        return [self.inv_vocab.get(i, \"<unk>\") for i in ids]\n",
    "\n",
    "out_vocab_transform = SimpleVocab(train_dataset.out_vocab)\n",
    "in_vocab_transform = SimpleVocab(train_dataset.in_vocab)\n",
    "\n",
    "# Translation function\n",
    "def translate(model, src_sentence, max_len=MAX_LEN):\n",
    "    model.eval()\n",
    "    src_tensor = simple_text_transform(src_sentence).to(DEVICE)\n",
    "    seq_len = src_tensor.size(1)\n",
    "    src_mask = torch.zeros(seq_len, seq_len, device=DEVICE).type(torch.float)\n",
    "    src_padding_mask = (src_tensor == train_dataset.in_vocab['<pad>']).to(DEVICE)\n",
    "    \n",
    "    ys = greedy_decode(model, src_tensor, src_mask, src_padding_mask, max_len=seq_len + 5, start_symbol=train_dataset.out_vocab['<sos>'])\n",
    "    tgt_tokens = ys.squeeze(0).cpu().numpy().tolist()\n",
    "    \n",
    "    tokens = out_vocab_transform.lookup_tokens(tgt_tokens)\n",
    "    num_words = len(src_sentence.split())\n",
    "    translation = \" \".join(tokens).replace(\"<sos>\", \"\").replace(\"<eos>\", \"\").strip()\n",
    "    if len(translation.split()) > num_words:\n",
    "        translation = \" \".join(translation.split()[:num_words])\n",
    "    return translation\n",
    "\n",
    "def simple_text_transform(sentence: str):\n",
    "    sentence = sentence.strip().lower()\n",
    "    sentence = sentence.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    tokens = sentence.split()\n",
    "    token_ids = [train_dataset.in_vocab.get(token, train_dataset.in_vocab['<unk>']) for token in tokens]\n",
    "    token_ids = token_ids[:MAX_LEN] + [train_dataset.in_vocab['<pad>']] * (MAX_LEN - len(token_ids))\n",
    "    return torch.tensor(token_ids, dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "# Training and Evaluation Functions\n",
    "def calculate_metrics(model, iterator, in_vocab, out_vocab, device, max_len, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_tokens = 0\n",
    "    bleu_scores = []\n",
    "    idx2word = {idx: word for word, idx in out_vocab.items()}\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    total_samples = len(iterator.dataset)\n",
    "    sample_size = max(1, total_samples // 100)\n",
    "    sampled_indices = random.sample(range(total_samples), sample_size)\n",
    "    sampled_dataset = torch.utils.data.Subset(iterator.dataset, sampled_indices)\n",
    "    sampled_loader = DataLoader(sampled_dataset, batch_size=iterator.batch_size, shuffle=False, pin_memory=True, num_workers=2, collate_fn=collate_fn)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for src, tgt in iterator:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            src_mask = torch.zeros(src.size(1), src.size(1), device=DEVICE).type(torch.float)\n",
    "            tgt_mask = generate_square_subsequent_mask(tgt.size(1) - 1).to(device)\n",
    "            src_padding_mask = (src == in_vocab['<pad>']).to(device)\n",
    "            tgt_padding_mask = (tgt[:, :-1] == out_vocab['<pad>']).to(device)\n",
    "            output = model(src, tgt[:, :-1], src_mask=src_mask, tgt_mask=tgt_mask, src_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask)\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.reshape(-1, output_dim)\n",
    "            tgt_flat = tgt[:, 1:].reshape(-1)\n",
    "            loss = criterion(output, tgt_flat)\n",
    "            total_loss += loss.item()\n",
    "            preds = output.argmax(dim=1)\n",
    "            non_pad_mask = tgt_flat != out_vocab['<pad>']\n",
    "            correct = (preds == tgt_flat) & non_pad_mask\n",
    "            total_correct += correct.sum().item()\n",
    "            total_tokens += non_pad_mask.sum().item()\n",
    "        for src, tgt in sampled_loader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            for i in range(src.shape[0]):\n",
    "                src_sent = src[i].unsqueeze(0)\n",
    "                tgt_sent = tgt[i].cpu().numpy()\n",
    "                src_mask = torch.zeros(src_sent.size(1), src_sent.size(1), device=DEVICE).type(torch.float)\n",
    "                src_padding_mask = (src_sent == in_vocab['<pad>']).to(device)\n",
    "                pred_sent = greedy_decode(model, src_sent, src_mask, src_padding_mask, max_len, out_vocab['<sos>'])\n",
    "                pred_sent = pred_sent.squeeze(0).cpu().numpy().tolist()\n",
    "                pred_tokens = [idx2word.get(idx, '<unk>') for idx in pred_sent if idx not in [out_vocab['<pad>'], out_vocab['<sos>'], out_vocab['<eos>']]]\n",
    "                ref_sent = [idx2word.get(idx, '<unk>') for idx in tgt_sent if idx not in [out_vocab['<pad>'], out_vocab['<sos>'], out_vocab['<eos>']]]\n",
    "                bleu = sentence_bleu([ref_sent], pred_tokens, smoothing_function=smoothie)\n",
    "                bleu_scores.append(bleu)\n",
    "    avg_loss = total_loss / len(iterator)\n",
    "    accuracy = total_correct / total_tokens if total_tokens > 0 else 0\n",
    "    avg_bleu = sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0\n",
    "    return avg_loss, accuracy, avg_bleu\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, criterion, in_vocab, out_vocab, max_len, device, num_epochs=NUM_EPOCHS, clip=1, patience=3):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    val_bleu_scores = []\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    log_file = \"/kaggle/working/results/training_log.txt\"\n",
    "    with open(log_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"Epoch,Train Loss,Val Loss,Val Accuracy,Val BLEU,VRAM (MB),Epoch Time (s)\\n\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        batch_count = 0\n",
    "        start_time = time.time()\n",
    "        for src, tgt in train_loader:\n",
    "            src, tgt = src.to(device, non_blocking=True), tgt.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad()\n",
    "            src_mask = torch.zeros(src.size(1), src.size(1), device=device).type(torch.float)\n",
    "            tgt_mask = generate_square_subsequent_mask(tgt.size(1) - 1).to(device)\n",
    "            src_padding_mask = (src == in_vocab['<pad>']).to(device)\n",
    "            tgt_padding_mask = (tgt[:, :-1] == out_vocab['<pad>']).to(device)\n",
    "            output = model(src, tgt[:, :-1], src_mask=src_mask, tgt_mask=tgt_mask, src_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask)\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.reshape(-1, output_dim)\n",
    "            tgt = tgt[:, 1:].reshape(-1)\n",
    "            loss = criterion(output, tgt)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            batch_count += 1\n",
    "        train_loss = epoch_loss / batch_count\n",
    "        val_loss, val_accuracy, val_bleu = calculate_metrics(model, val_loader, in_vocab, out_vocab, device, max_len, criterion)\n",
    "        epoch_time = time.time() - start_time\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        val_bleu_scores.append(val_bleu)\n",
    "        \n",
    "        with open(log_file, 'a', encoding='utf-8') as f:\n",
    "            f.write(f\"{epoch+1},{train_loss:.3f},{val_loss:.3f},{val_accuracy:.3f},{val_bleu:.3f},{torch.cuda.memory_allocated()/1024**2:.2f},{epoch_time:.2f}\\n\")\n",
    "        print(f'Epoch: {epoch+1:02}')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "        print(f'\\tVal Loss: {val_loss:.3f}')\n",
    "        print(f'\\tVal Accuracy: {val_accuracy:.3f}')\n",
    "        print(f'\\tVal BLEU: {val_bleu:.3f}')\n",
    "        print(f'\\tEpoch Time: {epoch_time:.2f} seconds')\n",
    "        print(f'\\tVRAM allocated: {torch.cuda.memory_allocated()/1024**2:.2f} MB')\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model, '/kaggle/working/results/transformer_best.pt')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f'Early stopping triggered after epoch {epoch+1}')\n",
    "                break\n",
    "    \n",
    "    # Plot and save metrics\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, train_losses, label='Train Loss')\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig('/kaggle/working/results/loss_plot.png')\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, val_accuracies, label='Validation Accuracy', color='green')\n",
    "    plt.title('Validation Accuracy over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig('/kaggle/working/results/accuracy_plot.png')\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, val_bleu_scores, label='Validation BLEU', color='blue')\n",
    "    plt.title('Validation BLEU Score over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('BLEU Score')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig('/kaggle/working/results/bleu_plot.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return train_losses, val_losses, val_accuracies, val_bleu_scores\n",
    "\n",
    "# Initialize model, criterion, optimizer\n",
    "model = Transformer(\n",
    "    src_vocab_size=len(train_dataset.in_vocab),\n",
    "    tgt_vocab_size=len(train_dataset.out_vocab),\n",
    "    d_model=DIM_MODEL,\n",
    "    n_heads=N_HEADS,\n",
    "    n_layers=N_LAYERS,\n",
    "    d_ff=D_FF,\n",
    "    max_len=MAX_LEN,\n",
    "    dropout=DROPOUT\n",
    ").to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=train_dataset.out_vocab['<pad>'])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "# Train the model\n",
    "train_losses, val_losses, val_accuracies, val_bleu_scores = train(\n",
    "    model, train_loader, val_loader, optimizer, criterion, \n",
    "    train_dataset.in_vocab, train_dataset.out_vocab, MAX_LEN, DEVICE\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7532443,
     "sourceId": 11977589,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
